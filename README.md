# Project Overview

In this project, we will compare different forecasting models on predicting Credit Default Swap (CDS) spreads during the Covid-19 pandemic. A CDS is a contract whereby one party (let’s call them party 1) makes periodical payments to another (party 2) for protection in the event that a third party (party 3) defaults on its contractual payments. This “protection” means that, if the third party defaults, the party providing the insurance (party 2) pays the total amount owed to party 1 (the company/individual making the periodic payments). CDS spreads, also referred to as “prices” or “rates” reflect the amount that the company buying protection (party 1) pays to the company providing the protection (party 2). These spreads are usually expressed as a percentage of the notional value of the party 3’s outstanding debt (technically in basis points, which is simply percentage * 100). 

Given the nature of time series forecasting with financial applications, we consider iterative 1-day forecasts to reflect the regular updating of beliefs as new data is observed. Despite this, we add an additional element to our research by fitting our chosen models’ parameters in the 5 years preceding the COVID-19 period, and then testing their performance during the pandemic. We consider two model “families”, with a total of 5 tested models: Autoregression (mean/level models): Simple Autoregression (AR(1)) and Autoregression Integrated Moving Average (ARIMA(1,1,1));  and ARCH-family models: Generalized;l Autoregressive Conditional Heteroskedasticity (ARCH(1)), Generalised ARCH (GARCH(1,1)) and GJR-GARCH(1,1,1) - all of which are by nature volatility models which we combine with a simple returns model. In each family, each model iteratively builds on the previous with the goal of better reflecting well established “stylised facts” of daily financial returns/price data (volatility clustering, leverage effects etc.). 

We consider several performance metrics to assess the relative performance of our models. We will test the RMSE of all models, as well as the Prediction Interval Sharpness (PIS) score, which measures the width of the confidence intervals of a given model as well as applies a penalty for lower prediction interval coverage probabilities (essentially neutralising the biases of having narrow intervals with low coverage and large intervals with high coverage). Additionally, considering the large number of companies for which we apply our time series forecast comparisons, we implement rescaling techniques to improve the interpretability of our forecast models performance at an aggregate level. Moreover, we use bootstrapping techniques to determine the distributional characteristics and consequently utilise nonparametric testing (namely, the Mann-Whitney U-test) to conduct pairwise comparisons of our models' forecasting performance. Finally, we compute the pairwise Diebold-Mariano (DM) forecasting accuracy test to compare each models performance against each other, as well as assess the frequency with which a single model outperforms all other models for a specific company. The CDS-rates use in our analysis are retrieved from Kaggle.

# Overview of Repository Structure

There are several key folders and files in this repository. We have two primary files for developing our forecasting models. The first of these is "ARIMA_model.ipynb", which contains the development and preliminary testing of the AR(1) and ARIMA(1,1,1) forecasting models. The second is "GARCH.ipynb", which contains the code used in the development of the ARCH(1), GARCH(1,1) and GJR-GARCH(1,1,1) forecasting models. Finally, we have a file "data_metrics_analysis.ipynb" which contains all the relevant tests and comparisons implemented in this project. 

The main supplementary folders to note are "datasets", which contains our original CDS spread data, as well as the forecast predictions and 95% confidence intervals for all of our models separately, and the "Figures" folder, which contains the figures used in our presentation.

Finally, we have our "Archive" folder, which contains some old code we considered in the early stages of this assignment, where we were still considering alternative project ideas. You can also find our final presentation within the repository. 

# Required Packages

The following (less common) packages are required for running the code from our various python files, alongside commonly used packages:
scipy, seaborn, statsmodels, arch, joblib, pmdarima, itertools
